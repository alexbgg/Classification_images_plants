{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#TODO: install \"hachoir\" Python library via \"python -m pip install hachoir\" instead of \"pip install hachoir\" to respect the virtual environment \n",
    "from hachoir.parser import createParser\n",
    "from hachoir.metadata import extractMetadata\n",
    "from sys import argv, stderr, exit\n",
    "import os\n",
    "from typing import Tuple\n",
    "import imageio.v3 as iio\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_oi = [\"Image width\", \"Image height\", \"Bits/pixel\", \"Pixel format\", \"MIME type\"] #as long as you don't wanna fetch other metadata, you are fine here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "#https://hachoir.readthedocs.io/en/latest/developer.html\n",
    "def image_metadata(filepath: str) -> Tuple[int, int, int, str, str]:\n",
    "    \"\"\"This function returns all the information related to the file passed in input.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The image file path.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, int, int, str, str]: \n",
    "            width in pixels as int, \n",
    "            height in pixels as int, \n",
    "            bits/pixel as int, \n",
    "            pixel format as string (RGB, YCbCr etc.), \n",
    "            MIME type as string (png, jpeg etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(argv) != 2:\n",
    "        print(\"usage: %s filename\" % argv[0], file=stderr)\n",
    "        exit(1)\n",
    "\n",
    "    col_names = []\n",
    "    values = []\n",
    "\n",
    "    parser = createParser(filepath)\n",
    "\n",
    "    if not parser:\n",
    "        print(\"Unable to parse file\", file=stderr)\n",
    "        exit(1)\n",
    "\n",
    "    with parser:\n",
    "        try:\n",
    "            metadata = extractMetadata(parser)\n",
    "        except Exception as err:\n",
    "            print(\"Metadata extraction error: %s\" % err)\n",
    "            metadata = None\n",
    "    if not metadata:\n",
    "        print(\"Unable to extract metadata\")\n",
    "        exit(1)\n",
    "\n",
    "    for line in metadata.exportPlaintext()[1:]:\n",
    "        line = line.removeprefix('- ')  \n",
    "        splist = line.split(\": \")\n",
    "        if splist[0] in col_oi:         \n",
    "            col_names.append(splist[0])\n",
    "            values.append(splist[1].removesuffix(' pixels').removeprefix('image/'))\n",
    "\n",
    "    width_px = int(values[col_names.index(\"Image width\")])\n",
    "    height_px = int(values[col_names.index(\"Image height\")])\n",
    "    bits_p_px = int(values[col_names.index(\"Bits/pixel\")])\n",
    "    px_format = values[col_names.index(\"Pixel format\")]\n",
    "    mime = values[col_names.index(\"MIME type\")]\n",
    "\n",
    "    return width_px, height_px, bits_p_px, px_format, mime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def populate_dataset(dataset: dict, directory: str):\n",
    "    \"\"\"This function populates the passed dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (dict): The dataset that will be populated.\n",
    "        directory (str): The directory where all the data is available.\n",
    "    \"\"\"\n",
    "    # Loop through all the files and folders in the directory\n",
    "    for folder_name in os.listdir(directory):\n",
    "        if os.path.isdir(os.path.join(directory, folder_name)):\n",
    "            for file_name in os.listdir(os.path.join(directory, folder_name)):\n",
    "                file_path = os.path.join(directory, folder_name, file_name)\n",
    "                width_px, height_px, bits_p_px, px_format, mime = image_metadata(file_path)\n",
    "                image=iio.imread(file_path)\n",
    "\n",
    "                dataset[\"folder_name\"].append(folder_name)\n",
    "                dataset[\"file_name\"].append(file_name)\n",
    "                dataset[\"width_px\"].append(width_px)\n",
    "                dataset[\"height_px\"].append(height_px)\n",
    "                dataset[\"bits_p_px\"].append(bits_p_px)\n",
    "                dataset[\"px_format\"].append(px_format)\n",
    "                dataset[\"mime\"].append(mime)\n",
    "                # number of channels (3rd dimension of the image array) \n",
    "                dataset[\"channels\"].append(image.shape[2])\n",
    "                # pixel-based major statistical features pro channel\n",
    "                for chn in range(3):\n",
    "                    dataset[f\"chn_{chn}_px_std\"].append(np.round(image[:,:,chn].std(),1))\n",
    "                    dataset[f\"chn_{chn}_px_min\"].append(np.percentile(image[:,:,chn],0))\n",
    "                    dataset[f\"chn_{chn}_px_q1\"].append(np.percentile(image[:,:,chn],25))\n",
    "                    dataset[f\"chn_{chn}_px_med\"].append(np.percentile(image[:,:,chn],50))\n",
    "                    dataset[f\"chn_{chn}_px_avg\"].append(np.round(image[:,:,chn].mean(),1))\n",
    "                    dataset[f\"chn_{chn}_px_q3\"].append(np.percentile(image[:,:,chn],75))\n",
    "                    dataset[f\"chn_{chn}_px_max\"].append(np.percentile(image[:,:,chn],100))\n",
    "                    dataset[f\"chn_{chn}_px_sum\"].append(image[:,:,chn].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'raw' is the main directory containing all the class-representing folders with respective files\n",
    "#TODO: replace the arguments with your full path directory names - TODO: for Unix systems, erase the first argument\n",
    "dataset_dir = os.path.join(\"C:\",os.sep,\"Users\",\"jeos\",\"Prj\",\"WB\",\"DST\",\"DS\",\"data\",\"raw\") \n",
    "\n",
    "# Create a DataFrame with the following columns in the dataset\n",
    "# Columns name: folder_name, file_name, width_px, height_px, bits_p_px, px_format, mime, channels, pro channel: {Q0..Q4 quantiles, std, mean, sum} of px\n",
    "data = defaultdict(list)\n",
    "\n",
    "populate_dataset(data, dataset_dir)\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv(os.path.join(dataset_dir,\"export_metadata_raw.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
